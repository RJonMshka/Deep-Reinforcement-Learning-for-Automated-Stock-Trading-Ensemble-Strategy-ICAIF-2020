{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RJonMshka/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/master/ensemble_original_3_month_window.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJCxfKUAXMtd"
      },
      "source": [
        "Cloning the Ensemble Strategy git repository for availablility of important modules and dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxzy-IaJUj4Y",
        "outputId": "40e949de-ffa2-4bb3-86e9-e626478a1823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020'...\n",
            "remote: Enumerating objects: 758, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 758 (delta 3), reused 6 (delta 2), pack-reused 749\u001b[K\n",
            "Receiving objects: 100% (758/758), 37.53 MiB | 6.89 MiB/s, done.\n",
            "Resolving deltas: 100% (304/304), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aepUxxv9XZ3-",
        "outputId": "c2549167-0507-413e-a2ff-71b6a1a7429e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020\n"
          ]
        }
      ],
      "source": [
        "%cd Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "duiY8mabYhoR",
        "outputId": "f35c9316-adf8-4f1d-a650-aaacd2b91938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.16.4\n",
            "  Downloading numpy-1.16.4-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting pandas==1.0.3\n",
            "  Downloading pandas-1.0.3-cp37-cp37m-manylinux1_x86_64.whl (10.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0 MB 55.8 MB/s \n",
            "\u001b[?25hCollecting stockstats\n",
            "  Downloading stockstats-0.4.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting scikit-learn==0.21.0\n",
            "  Downloading scikit_learn-0.21.0-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 46.7 MB/s \n",
            "\u001b[?25hCollecting gym==0.15.3\n",
            "  Downloading gym-0.15.3.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 68.4 MB/s \n",
            "\u001b[?25hCollecting stable-baselines[mpi]\n",
            "  Downloading stable_baselines-2.10.2-py3-none-any.whl (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 61.7 MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.15.4\n",
            "  Downloading tensorflow-1.15.4-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting joblib==0.15.1\n",
            "  Downloading joblib-0.15.1-py3-none-any.whl (298 kB)\n",
            "\u001b[K     |████████████████████████████████| 298 kB 64.4 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.2.1\n",
            "  Downloading matplotlib-3.2.1-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 56.0 MB/s \n",
            "\u001b[?25hCollecting pytest<6.0.0,>=5.3.2\n",
            "  Downloading pytest-5.4.3-py3-none-any.whl (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 86.3 MB/s \n",
            "\u001b[?25hCollecting setuptools<42.0.0,>=41.4.0\n",
            "  Downloading setuptools-41.6.0-py2.py3-none-any.whl (582 kB)\n",
            "\u001b[K     |████████████████████████████████| 582 kB 74.1 MB/s \n",
            "\u001b[?25hCollecting wheel<0.34.0,>=0.33.6\n",
            "  Downloading wheel-0.33.6-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.3->-r requirements.txt (line 3)) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.3->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.0->-r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gym==0.15.3->-r requirements.txt (line 6)) (1.15.0)\n",
            "Collecting pyglet<=1.3.2,>=1.2.0\n",
            "  Downloading pyglet-1.3.2-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 62.1 MB/s \n",
            "\u001b[?25hCollecting cloudpickle~=1.2.0\n",
            "  Downloading cloudpickle-1.2.2-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (3.17.3)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.44.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (0.8.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 53.8 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->-r requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.1->-r requirements.txt (line 13)) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.1->-r requirements.txt (line 13)) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.1->-r requirements.txt (line 13)) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (21.3)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (1.11.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (4.11.3)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (8.12.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest<6.0.0,>=5.3.2->-r requirements.txt (line 16)) (4.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4->-r requirements.txt (line 8)) (3.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym==0.15.3->-r requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->-r requirements.txt (line 8)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->-r requirements.txt (line 8)) (3.3.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.4->-r requirements.txt (line 8)) (1.5.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]->-r requirements.txt (line 7)) (4.1.2.30)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]->-r requirements.txt (line 7)) (0.17.3)\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.3.tar.gz (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 50.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gym[atari,classic_control]>=0.11\n",
            "  Downloading gym-0.23.1.tar.gz (626 kB)\n",
            "\u001b[K     |████████████████████████████████| 626 kB 68.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.23.0.tar.gz (624 kB)\n",
            "\u001b[K     |████████████████████████████████| 624 kB 70.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.22.0.tar.gz (631 kB)\n",
            "\u001b[K     |████████████████████████████████| 631 kB 69.7 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 61.3 MB/s \n",
            "\u001b[?25h  Downloading gym-0.20.0.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 65.7 MB/s \n",
            "\u001b[?25h  Downloading gym-0.19.0.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 53.3 MB/s \n",
            "\u001b[?25h  Downloading gym-0.18.3.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 29.8 MB/s \n",
            "\u001b[?25h  Downloading gym-0.18.0.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 60.0 MB/s \n",
            "\u001b[?25h  Downloading gym-0.17.2.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 59.2 MB/s \n",
            "\u001b[?25h  Downloading gym-0.17.1.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 49.7 MB/s \n",
            "\u001b[?25h  Downloading gym-0.17.0.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 50.2 MB/s \n",
            "\u001b[?25h  Downloading gym-0.16.0.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 51.2 MB/s \n",
            "\u001b[?25h  Downloading gym-0.15.7.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 53.5 MB/s \n",
            "\u001b[?25h  Downloading gym-0.15.6.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 44.8 MB/s \n",
            "\u001b[?25h  Downloading gym-0.15.4.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: atari_py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym==0.15.3->-r requirements.txt (line 6)) (0.2.9)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym==0.15.3->-r requirements.txt (line 6)) (7.1.2)\n",
            "Building wheels for collected packages: gym, gast, mpi4py\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.15.3-py3-none-any.whl size=1644970 sha256=c4f1d22d5da1fe29c5fdbb02f6299679d99e67d35b95e4f79e6a25e65e50fcce\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/16/6b/2250ca4f9f050a4d27d8bed287e57bbb3c33fc4066f557cc75\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=31e1894b8efe8eea974113634effa8e7ff0cae4bafd69b01607b8a2f6c5e7ac7\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.3-cp37-cp37m-linux_x86_64.whl size=2185293 sha256=a69834932ca28b53a80b73f589713770951f1c94baff032682bc7880b3b95930\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/07/14/6a0c63fa2c6e473c6edc40985b7d89f05c61ff25ee7f0ad9ac\n",
            "Successfully built gym gast mpi4py\n",
            "Installing collected packages: numpy, pyglet, cloudpickle, gym, wheel, setuptools, pandas, matplotlib, joblib, tensorflow-estimator, tensorboard, stable-baselines, pluggy, mpi4py, keras-applications, gast, tensorflow, stockstats, scikit-learn, pytest\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: pyglet\n",
            "    Found existing installation: pyglet 1.5.0\n",
            "    Uninstalling pyglet-1.5.0:\n",
            "      Successfully uninstalled pyglet-1.5.0\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.37.1\n",
            "    Uninstalling wheel-0.37.1:\n",
            "      Successfully uninstalled wheel-0.37.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.1.0\n",
            "    Uninstalling joblib-1.1.0:\n",
            "      Successfully uninstalled joblib-1.1.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.21.0 which is incompatible.\n",
            "xarray 0.18.2 requires numpy>=1.17, but you have numpy 1.16.4 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires cloudpickle>=1.3, but you have cloudpickle 1.2.2 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.16.4 which is incompatible.\n",
            "scikit-image 0.18.3 requires numpy>=1.16.5, but you have numpy 1.16.4 which is incompatible.\n",
            "pywavelets 1.3.0 requires numpy>=1.17.3, but you have numpy 1.16.4 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.16.4 which is incompatible.\n",
            "pyarrow 6.0.1 requires numpy>=1.16.6, but you have numpy 1.16.4 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.16.4 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.4 which is incompatible.\n",
            "jaxlib 0.3.2+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.16.4 which is incompatible.\n",
            "jax 0.3.4 requires numpy>=1.19, but you have numpy 1.16.4 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.21.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 1.0.3 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 1.0.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.16.4 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed cloudpickle-1.2.2 gast-0.2.2 gym-0.15.3 joblib-0.15.1 keras-applications-1.0.8 matplotlib-3.2.1 mpi4py-3.1.3 numpy-1.16.4 pandas-1.0.3 pluggy-0.13.1 pyglet-1.3.2 pytest-5.4.3 scikit-learn-0.21.0 setuptools-41.6.0 stable-baselines-2.10.2 stockstats-0.4.1 tensorboard-1.15.0 tensorflow-1.15.4 tensorflow-estimator-1.15.1 wheel-0.33.6\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbhZoZYWqulj"
      },
      "source": [
        "Setting up the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQUhxgo2q0tt",
        "outputId": "7bc0f679-187d-4bbc-83ab-591301d1927a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
            "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
          ]
        }
      ],
      "source": [
        "# common library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import gym\n",
        "import os\n",
        "\n",
        "# RL models from stable-baselines\n",
        "from stable_baselines import PPO2\n",
        "from stable_baselines import A2C\n",
        "from stable_baselines import DDPG\n",
        "from stable_baselines import TD3\n",
        "\n",
        "from stable_baselines.ddpg.policies import DDPGPolicy\n",
        "from stable_baselines.common.policies import MlpPolicy, MlpLstmPolicy, MlpLnLstmPolicy\n",
        "from stable_baselines.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec\n",
        "from stable_baselines.common.vec_env import DummyVecEnv\n",
        "from preprocessing.preprocessors import *\n",
        "from config import config\n",
        "from model.models import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RVR5ZndMyCh3"
      },
      "outputs": [],
      "source": [
        "from gym.utils import seeding\n",
        "from gym import spaces\n",
        "import pickle\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# shares normalization factor\n",
        "# 100 shares per trade\n",
        "HMAX_NORMALIZE = 100\n",
        "# initial amount of money we have in our account\n",
        "INITIAL_ACCOUNT_BALANCE=1000000\n",
        "# total number of stocks in our portfolio\n",
        "STOCK_DIM = 30\n",
        "# transaction fee: 1/1000 reasonable percentage\n",
        "TRANSACTION_FEE_PERCENT = 0.001\n",
        "\n",
        "# turbulence index: 90-150 reasonable threshold\n",
        "#TURBULENCE_THRESHOLD = 140\n",
        "REWARD_SCALING = 1e-4\n",
        "\n",
        "class StockEnvValidation(gym.Env):\n",
        "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, df, day = 0, turbulence_threshold=140, iteration=''):\n",
        "        #super(StockEnv, self).__init__()\n",
        "        #money = 10 , scope = 1\n",
        "        self.day = day\n",
        "        self.df = df\n",
        "        # action_space normalization and shape is STOCK_DIM\n",
        "        self.action_space = spaces.Box(low = -1, high = 1,shape = (STOCK_DIM,)) \n",
        "        # Shape = 181: [Current Balance]+[prices 1-30]+[owned shares 1-30] \n",
        "        # +[macd 1-30]+ [rsi 1-30] + [cci 1-30] + [adx 1-30]\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape = (181,))\n",
        "        # load data from a pandas dataframe\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.terminal = False     \n",
        "        self.turbulence_threshold = turbulence_threshold\n",
        "        # initalize state\n",
        "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n",
        "                      self.data.adjcp.values.tolist() + \\\n",
        "                      [0]*STOCK_DIM + \\\n",
        "                      self.data.macd.values.tolist() + \\\n",
        "                      self.data.rsi.values.tolist() + \\\n",
        "                      self.data.cci.values.tolist() + \\\n",
        "                      self.data.adx.values.tolist()\n",
        "        # initialize reward\n",
        "        self.reward = 0\n",
        "        self.turbulence = 0\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        # memorize all the total balance change\n",
        "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n",
        "        self.rewards_memory = []\n",
        "        #self.reset()\n",
        "        self._seed()\n",
        "        \n",
        "        self.iteration=iteration\n",
        "\n",
        "\n",
        "    def _sell_stock(self, index, action):\n",
        "        # perform sell action based on the sign of the action\n",
        "        if self.turbulence<self.turbulence_threshold:\n",
        "            if self.state[index+STOCK_DIM+1] > 0:\n",
        "                #update balance\n",
        "                self.state[0] += \\\n",
        "                self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n",
        "                 (1- TRANSACTION_FEE_PERCENT)\n",
        "                \n",
        "                self.state[index+STOCK_DIM+1] -= min(abs(action), self.state[index+STOCK_DIM+1])\n",
        "                self.cost +=self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n",
        "                 TRANSACTION_FEE_PERCENT\n",
        "                self.trades+=1\n",
        "            else:\n",
        "                pass\n",
        "        else:\n",
        "            # if turbulence goes over threshold, just clear out all positions \n",
        "            if self.state[index+STOCK_DIM+1] > 0:\n",
        "                #update balance\n",
        "                self.state[0] += self.state[index+1]*self.state[index+STOCK_DIM+1]* \\\n",
        "                              (1- TRANSACTION_FEE_PERCENT)\n",
        "                self.state[index+STOCK_DIM+1] =0\n",
        "                self.cost += self.state[index+1]*self.state[index+STOCK_DIM+1]* \\\n",
        "                              TRANSACTION_FEE_PERCENT\n",
        "                self.trades+=1\n",
        "            else:\n",
        "                pass\n",
        "    \n",
        "    def _buy_stock(self, index, action):\n",
        "        # perform buy action based on the sign of the action\n",
        "        if self.turbulence< self.turbulence_threshold:\n",
        "            available_amount = self.state[0] // self.state[index+1]\n",
        "            # print('available_amount:{}'.format(available_amount))\n",
        "            \n",
        "            #update balance\n",
        "            self.state[0] -= self.state[index+1]*min(available_amount, action)* \\\n",
        "                              (1+ TRANSACTION_FEE_PERCENT)\n",
        "\n",
        "            self.state[index+STOCK_DIM+1] += min(available_amount, action)\n",
        "            \n",
        "            self.cost+=self.state[index+1]*min(available_amount, action)* \\\n",
        "                              TRANSACTION_FEE_PERCENT\n",
        "            self.trades+=1\n",
        "        else:\n",
        "            # if turbulence goes over threshold, just stop buying\n",
        "            pass\n",
        "        \n",
        "    def step(self, actions):\n",
        "        # print(self.day)\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "        # print(actions)\n",
        "\n",
        "        if self.terminal:\n",
        "            plt.plot(self.asset_memory,'r')\n",
        "            plt.savefig('results/account_value_validation_{}.png'.format(self.iteration))\n",
        "            plt.close()\n",
        "            df_total_value = pd.DataFrame(self.asset_memory)\n",
        "            df_total_value.to_csv('results/account_value_validation_{}.csv'.format(self.iteration))\n",
        "            end_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
        "            #print(\"previous_total_asset:{}\".format(self.asset_memory[0]))           \n",
        "\n",
        "            #print(\"end_total_asset:{}\".format(end_total_asset))\n",
        "            #print(\"total_reward:{}\".format(self.state[0]+sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):61]))- self.asset_memory[0] ))\n",
        "            #print(\"total_cost: \", self.cost)\n",
        "            #print(\"total trades: \", self.trades)\n",
        "\n",
        "            df_total_value.columns = ['account_value']\n",
        "            df_total_value['daily_return']=df_total_value.pct_change(1)\n",
        "            sharpe = (4**0.5)*df_total_value['daily_return'].mean()/ \\\n",
        "                  df_total_value['daily_return'].std()\n",
        "            #print(\"Sharpe: \",sharpe)\n",
        "            \n",
        "            #df_rewards = pd.DataFrame(self.rewards_memory)\n",
        "            #df_rewards.to_csv('results/account_rewards_trade_{}.csv'.format(self.iteration))\n",
        "            \n",
        "            # print('total asset: {}'.format(self.state[0]+ sum(np.array(self.state[1:29])*np.array(self.state[29:]))))\n",
        "            #with open('obs.pkl', 'wb') as f:  \n",
        "            #    pickle.dump(self.state, f)\n",
        "            \n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            # print(np.array(self.state[1:29]))\n",
        "\n",
        "            actions = actions * HMAX_NORMALIZE\n",
        "            #actions = (actions.astype(int))\n",
        "            if self.turbulence>=self.turbulence_threshold:\n",
        "                actions=np.array([-HMAX_NORMALIZE]*STOCK_DIM)\n",
        "            begin_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
        "            #print(\"begin_total_asset:{}\".format(begin_total_asset))\n",
        "            \n",
        "            argsort_actions = np.argsort(actions)\n",
        "            \n",
        "            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\n",
        "            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\n",
        "\n",
        "            for index in sell_index:\n",
        "                # print('take sell action'.format(actions[index]))\n",
        "                self._sell_stock(index, actions[index])\n",
        "\n",
        "            for index in buy_index:\n",
        "                # print('take buy action: {}'.format(actions[index]))\n",
        "                self._buy_stock(index, actions[index])\n",
        "\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day,:]         \n",
        "            self.turbulence = self.data['turbulence'].values[0]\n",
        "            #print(self.turbulence)\n",
        "            #load next state\n",
        "            # print(\"stock_shares:{}\".format(self.state[29:]))\n",
        "            self.state =  [self.state[0]] + \\\n",
        "                    self.data.adjcp.values.tolist() + \\\n",
        "                    list(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]) + \\\n",
        "                    self.data.macd.values.tolist() + \\\n",
        "                    self.data.rsi.values.tolist() + \\\n",
        "                    self.data.cci.values.tolist() + \\\n",
        "                    self.data.adx.values.tolist()\n",
        "            \n",
        "            end_total_asset = self.state[0]+ \\\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n",
        "            self.asset_memory.append(end_total_asset)\n",
        "            #print(\"end_total_asset:{}\".format(end_total_asset))\n",
        "            \n",
        "            self.reward = end_total_asset - begin_total_asset            \n",
        "            # print(\"step_reward:{}\".format(self.reward))\n",
        "            self.rewards_memory.append(self.reward)\n",
        "            \n",
        "            self.reward = self.reward*REWARD_SCALING\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):  \n",
        "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.turbulence = 0\n",
        "        self.cost = 0\n",
        "        self.trades = 0\n",
        "        self.terminal = False \n",
        "        #self.iteration=self.iteration\n",
        "        self.rewards_memory = []\n",
        "        #initiate state\n",
        "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n",
        "                      self.data.adjcp.values.tolist() + \\\n",
        "                      [0]*STOCK_DIM + \\\n",
        "                      self.data.macd.values.tolist() + \\\n",
        "                      self.data.rsi.values.tolist()  + \\\n",
        "                      self.data.cci.values.tolist()  + \\\n",
        "                      self.data.adx.values.tolist() \n",
        "            \n",
        "        return self.state\n",
        "    \n",
        "    def render(self, mode='human',close=False):\n",
        "        return self.state\n",
        "    \n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nCytswFX0LvF"
      },
      "outputs": [],
      "source": [
        "def train_A2C(env_train, model_name, timesteps=25000):\n",
        "    \"\"\"A2C model\"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "    model = A2C('MlpPolicy', env_train, verbose=0)\n",
        "    model.learn(total_timesteps=timesteps)\n",
        "    end = time.time()\n",
        "\n",
        "    model.save(f\"{config.TRAINED_MODEL_DIR}/{model_name}\")\n",
        "    print('Training time (A2C): ', (end - start) / 60, ' minutes')\n",
        "    return model\n",
        "\n",
        "def train_DDPG(env_train, model_name, timesteps=10000):\n",
        "    \"\"\"DDPG model\"\"\"\n",
        "\n",
        "    # add the noise objects for DDPG\n",
        "    n_actions = env_train.action_space.shape[-1]\n",
        "    param_noise = None\n",
        "    action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n",
        "\n",
        "    start = time.time()\n",
        "    model = DDPG('MlpPolicy', env_train, param_noise=param_noise, action_noise=action_noise)\n",
        "    model.learn(total_timesteps=timesteps)\n",
        "    end = time.time()\n",
        "\n",
        "    model.save(f\"{config.TRAINED_MODEL_DIR}/{model_name}\")\n",
        "    print('Training time (DDPG): ', (end-start)/60,' minutes')\n",
        "    return model\n",
        "\n",
        "def train_PPO(env_train, model_name, timesteps=50000):\n",
        "    \"\"\"PPO model\"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "    model = PPO2('MlpPolicy', env_train, ent_coef = 0.005, nminibatches = 8)\n",
        "    #model = PPO2('MlpPolicy', env_train, ent_coef = 0.005)\n",
        "\n",
        "    model.learn(total_timesteps=timesteps)\n",
        "    end = time.time()\n",
        "\n",
        "    model.save(f\"{config.TRAINED_MODEL_DIR}/{model_name}\")\n",
        "    print('Training time (PPO): ', (end - start) / 60, ' minutes')\n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "D3c3PRgpt-7q"
      },
      "outputs": [],
      "source": [
        "def DRL_prediction(df,\n",
        "                   model,\n",
        "                   name,\n",
        "                   last_state,\n",
        "                   iter_num,\n",
        "                   unique_trade_date,\n",
        "                   rebalance_window,\n",
        "                   turbulence_threshold,\n",
        "                   initial):\n",
        "    ### make a prediction based on trained model###\n",
        "\n",
        "    ## trading env\n",
        "    trade_data = data_split(df, start=unique_trade_date[iter_num - rebalance_window], end=unique_trade_date[iter_num])\n",
        "    env_trade = DummyVecEnv([lambda: StockEnvTrade(trade_data,\n",
        "                                                   turbulence_threshold=turbulence_threshold,\n",
        "                                                   initial=initial,\n",
        "                                                   previous_state=last_state,\n",
        "                                                   model_name=name,\n",
        "                                                   iteration=iter_num)])\n",
        "    obs_trade = env_trade.reset()\n",
        "\n",
        "    for i in range(len(trade_data.index.unique())):\n",
        "        action, _states = model.predict(obs_trade)\n",
        "        obs_trade, rewards, dones, info = env_trade.step(action)\n",
        "        if i == (len(trade_data.index.unique()) - 2):\n",
        "            # print(env_test.render())\n",
        "            last_state = env_trade.render()\n",
        "\n",
        "    df_last_state = pd.DataFrame({'last_state': last_state})\n",
        "    df_last_state.to_csv('results/last_state_{}_{}.csv'.format(name, i), index=False)\n",
        "    return last_state\n",
        "\n",
        "\n",
        "\n",
        "def DRL_validation(model, test_data, test_env, test_obs) -> None:\n",
        "    ###validation process###\n",
        "    for i in range(len(test_data.index.unique())):\n",
        "        action, _states = model.predict(test_obs)\n",
        "        test_obs, rewards, dones, info = test_env.step(action)\n",
        "\n",
        "\n",
        "def get_validation_sharpe(iteration):\n",
        "    ###Calculate Sharpe ratio based on validation results###\n",
        "    df_total_value = pd.read_csv('results/account_value_validation_{}.csv'.format(iteration), index_col=0)\n",
        "    df_total_value.columns = ['account_value_train']\n",
        "    df_total_value['daily_return'] = df_total_value.pct_change(1)\n",
        "    sharpe = (4 ** 0.5) * df_total_value['daily_return'].mean() / \\\n",
        "             df_total_value['daily_return'].std()\n",
        "    return sharpe\n",
        "\n",
        "\n",
        "def run_ensemble_strategy(df, unique_trade_date, rebalance_window, validation_window) -> None:\n",
        "    \"\"\"Ensemble Strategy that combines PPO, A2C and DDPG\"\"\"\n",
        "    print(\"============Start Ensemble Strategy============\")\n",
        "    # for ensemble model, it's necessary to feed the last state\n",
        "    # of the previous model to the current model as the initial state\n",
        "    last_state_ensemble = []\n",
        "\n",
        "    ppo_sharpe_list = []\n",
        "    ddpg_sharpe_list = []\n",
        "    a2c_sharpe_list = []\n",
        "\n",
        "    model_use = []\n",
        "\n",
        "    # based on the analysis of the in-sample data\n",
        "    #turbulence_threshold = 140\n",
        "    insample_turbulence = df[(df.datadate<20151000) & (df.datadate>=20090000)]\n",
        "    insample_turbulence = insample_turbulence.drop_duplicates(subset=['datadate'])\n",
        "    insample_turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, .90)\n",
        "\n",
        "    start = time.time()\n",
        "    print(\"length:\", rebalance_window + validation_window, len(unique_trade_date), rebalance_window)\n",
        "    for i in range(rebalance_window + validation_window, len(unique_trade_date), rebalance_window):\n",
        "        print(\"============================================\")\n",
        "        ## initial state is empty\n",
        "        if i - rebalance_window - validation_window == 0:\n",
        "            # inital state\n",
        "            initial = True\n",
        "        else:\n",
        "            # previous state\n",
        "            initial = False\n",
        "\n",
        "        # Tuning trubulence index based on historical data\n",
        "        # Turbulence lookback window is one quarter\n",
        "        end_date_index = df.index[df[\"datadate\"] == unique_trade_date[i - rebalance_window - validation_window]].to_list()[-1]\n",
        "        start_date_index = end_date_index - validation_window*30 + 1\n",
        "\n",
        "        historical_turbulence = df.iloc[start_date_index:(end_date_index + 1), :]\n",
        "        \n",
        "        #historical_turbulence = df[(df.datadate<unique_trade_date[i - rebalance_window - validation_window]) & (df.datadate>=(unique_trade_date[i - rebalance_window - validation_window - 63]))]\n",
        "\n",
        "\n",
        "        historical_turbulence = historical_turbulence.drop_duplicates(subset=['datadate'])\n",
        "\n",
        "        historical_turbulence_mean = np.mean(historical_turbulence.turbulence.values)\n",
        "        print(\"insample turbulence threshold: \", insample_turbulence_threshold)\n",
        "        print(\"historic turbulence mean: \", historical_turbulence_mean)\n",
        "\n",
        "        if historical_turbulence_mean > insample_turbulence_threshold:\n",
        "            # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\n",
        "            # then we assume that the current market is volatile,\n",
        "            # therefore we set the 90% quantile of insample turbulence data as the turbulence threshold\n",
        "            # meaning the current turbulence can't exceed the 90% quantile of insample turbulence data\n",
        "            turbulence_threshold = insample_turbulence_threshold\n",
        "        else:\n",
        "            # if the mean of the historical data is less than the 90% quantile of insample turbulence data\n",
        "            # then we tune up the turbulence_threshold, meaning we lower the risk\n",
        "            turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, 1)\n",
        "        print(\"turbulence_threshold: \", turbulence_threshold)\n",
        "\n",
        "        ############## Environment Setup starts ##############\n",
        "        ## training env\n",
        "        train = data_split(df, start=20090000, end=unique_trade_date[i - rebalance_window - validation_window])\n",
        "        env_train = DummyVecEnv([lambda: StockEnvTrain(train)])\n",
        "\n",
        "        print(\"train data start: \", 20090000)\n",
        "        print(\"train data end: \", unique_trade_date[i - rebalance_window - validation_window])\n",
        "\n",
        "        ## validation env\n",
        "        validation = data_split(df, start=unique_trade_date[i - rebalance_window - validation_window],\n",
        "                                end=unique_trade_date[i - rebalance_window])\n",
        "        env_val = DummyVecEnv([lambda: StockEnvValidation(validation,\n",
        "                                                          turbulence_threshold=turbulence_threshold,\n",
        "                                                          iteration=i)])\n",
        "        print(\"validation data start: \", unique_trade_date[i - rebalance_window - validation_window])\n",
        "        print(\"validation data end: \", unique_trade_date[i - rebalance_window])\n",
        "        \n",
        "        obs_val = env_val.reset()\n",
        "        ############## Environment Setup ends ##############\n",
        "\n",
        "        ############## Training and Validation starts ##############\n",
        "        print(\"======Model training from: \", 20090000, \"to \",\n",
        "              unique_trade_date[i - rebalance_window - validation_window])\n",
        "        # print(\"training: \",len(data_split(df, start=20090000, end=test.datadate.unique()[i-rebalance_window]) ))\n",
        "        # print(\"==============Model Training===========\")\n",
        "        print(\"======A2C Training========\")\n",
        "        model_a2c = train_A2C(env_train, model_name=\"A2C_30k_dow_{}\".format(i), timesteps=3000)\n",
        "        print(\"start:\", i - rebalance_window - validation_window)\n",
        "        print(\"end: \", i - rebalance_window)\n",
        "        print(\"======A2C Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
        "              unique_trade_date[i - rebalance_window])\n",
        "        DRL_validation(model=model_a2c, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
        "        sharpe_a2c = get_validation_sharpe(i)\n",
        "        print(\"A2C Sharpe Ratio: \", sharpe_a2c)\n",
        "\n",
        "        print(\"======PPO Training========\")\n",
        "        model_ppo = train_PPO(env_train, model_name=\"PPO_100k_dow_{}\".format(i), timesteps=10000)\n",
        "        print(\"======PPO Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
        "              unique_trade_date[i - rebalance_window])\n",
        "        DRL_validation(model=model_ppo, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
        "        sharpe_ppo = get_validation_sharpe(i)\n",
        "        print(\"PPO Sharpe Ratio: \", sharpe_ppo)\n",
        "\n",
        "        print(\"======DDPG Training========\")\n",
        "        model_ddpg = train_DDPG(env_train, model_name=\"DDPG_10k_dow_{}\".format(i), timesteps=2000)\n",
        "        #model_ddpg = train_TD3(env_train, model_name=\"DDPG_10k_dow_{}\".format(i), timesteps=20000)\n",
        "        print(\"======DDPG Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n",
        "              unique_trade_date[i - rebalance_window])\n",
        "        DRL_validation(model=model_ddpg, test_data=validation, test_env=env_val, test_obs=obs_val)\n",
        "        sharpe_ddpg = get_validation_sharpe(i)\n",
        "\n",
        "        ppo_sharpe_list.append(sharpe_ppo)\n",
        "        a2c_sharpe_list.append(sharpe_a2c)\n",
        "        ddpg_sharpe_list.append(sharpe_ddpg)\n",
        "\n",
        "        # Model Selection based on sharpe ratio\n",
        "        if (sharpe_ppo >= sharpe_a2c) & (sharpe_ppo >= sharpe_ddpg):\n",
        "            model_ensemble = model_ppo\n",
        "            model_use.append('PPO')\n",
        "        elif (sharpe_a2c > sharpe_ppo) & (sharpe_a2c > sharpe_ddpg):\n",
        "            model_ensemble = model_a2c\n",
        "            model_use.append('A2C')\n",
        "        else:\n",
        "            model_ensemble = model_ddpg\n",
        "            model_use.append('DDPG')\n",
        "        ############## Training and Validation ends ##############\n",
        "\n",
        "        ############## Trading starts ##############\n",
        "        print(\"======Trading from: \", unique_trade_date[i - rebalance_window], \"to \", unique_trade_date[i])\n",
        "        #print(\"Used Model: \", model_ensemble)\n",
        "        last_state_ensemble = DRL_prediction(df=df, model=model_ensemble, name=\"ensemble\",\n",
        "                                             last_state=last_state_ensemble, iter_num=i,\n",
        "                                             unique_trade_date=unique_trade_date,\n",
        "                                             rebalance_window=rebalance_window,\n",
        "                                             turbulence_threshold=turbulence_threshold,\n",
        "                                             initial=initial)\n",
        "        # print(\"============Trading Done============\")\n",
        "        ############## Trading ends ##############\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"Ensemble Strategy took: \", (end - start) / 60, \" minutes\")\n",
        "    return (model_use, a2c_sharpe_list, ppo_sharpe_list, ddpg_sharpe_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "zU9RtkNRuy2p"
      },
      "outputs": [],
      "source": [
        "def run_model() -> None:\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "\n",
        "    # read and preprocess data\n",
        "    preprocessed_path = \"done_data.csv\"\n",
        "    if os.path.exists(preprocessed_path):\n",
        "        data = pd.read_csv(preprocessed_path, index_col=0)\n",
        "    else:\n",
        "        data = preprocess_data()\n",
        "        data = add_turbulence(data)\n",
        "        data.to_csv(preprocessed_path)\n",
        "\n",
        "    print(data.head())\n",
        "    print(data.size)\n",
        "\n",
        "    # 2015/10/01 is the date that validation starts\n",
        "    # 2016/01/01 is the date that real trading starts\n",
        "    # unique_trade_date needs to start from 2015/10/01 for validation purpose\n",
        "    unique_trade_date = data[(data.datadate > 20151001)&(data.datadate <= 20200707)].datadate.unique()\n",
        "    print(unique_trade_date)\n",
        "\n",
        "    # rebalance_window is the number of months to retrain the model\n",
        "    # validation_window is the number of months to validation the model and select for trading\n",
        "    rebalance_window = 63\n",
        "    validation_window = 63\n",
        "    \n",
        "    ## Ensemble Strategy\n",
        "    return run_ensemble_strategy(df=data, \n",
        "                          unique_trade_date= unique_trade_date,\n",
        "                          rebalance_window = rebalance_window,\n",
        "                          validation_window=validation_window)\n",
        "\n",
        "    #_logger.info(f\"saving model version: {_version}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-COVh8IQu2ij",
        "outputId": "2827e1e8-7dc8-40b7-f132-416db412f40a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   datadate   tic      adjcp       open       high        low      volume  \\\n",
            "0  20090102  AAPL  12.964286  12.268571  13.005714  12.165714  26641980.0   \n",
            "1  20090102   AXP  19.330000  18.570000  19.520000  18.400000  10955620.0   \n",
            "2  20090102    BA  45.250000  42.800000  45.560000  42.780000   7010171.0   \n",
            "3  20090102   CAT  46.910000  44.910000  46.980000  44.710000   7116726.0   \n",
            "4  20090102  CSCO  16.960000  16.410000  17.000000  16.250000  40977480.0   \n",
            "\n",
            "   macd    rsi        cci    adx  turbulence  \n",
            "0   0.0  100.0  66.666667  100.0         0.0  \n",
            "1   0.0  100.0  66.666667  100.0         0.0  \n",
            "2   0.0  100.0  66.666667  100.0         0.0  \n",
            "3   0.0    0.0  66.666667  100.0         0.0  \n",
            "4   0.0  100.0  66.666667  100.0         0.0  \n",
            "1053360\n",
            "[20151002 20151005 20151006 ... 20200702 20200706 20200707]\n",
            "============Start Ensemble Strategy============\n",
            "length: 126 1198 63\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  86.50335037987244\n",
            "turbulence_threshold:  171.0940715631016\n",
            "train data start:  20090000\n",
            "train data end:  20151002\n",
            "validation data start:  20151002\n",
            "validation data end:  20160104\n",
            "======Model training from:  20090000 to  20151002\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.15697685877482095  minutes\n",
            "start: 0\n",
            "end:  63\n",
            "======A2C Validation from:  20151002 to  20160104\n",
            "A2C Sharpe Ratio:  0.02741843321550068\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5825606465339661  minutes\n",
            "======PPO Validation from:  20151002 to  20160104\n",
            "PPO Sharpe Ratio:  -0.06593909665749961\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.26692872047424315  minutes\n",
            "======DDPG Validation from:  20151002 to  20160104\n",
            "======Trading from:  20160104 to  20160405\n",
            "previous_total_asset:1000000\n",
            "end_total_asset:1068309.3892576096\n",
            "total_reward:68309.38925760961\n",
            "total_cost:  999.0007504144621\n",
            "total trades:  806\n",
            "Sharpe:  0.22362208153396093\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  109.3702720783417\n",
            "turbulence_threshold:  96.08032158358223\n",
            "train data start:  20090000\n",
            "train data end:  20160104\n",
            "validation data start:  20160104\n",
            "validation data end:  20160405\n",
            "======Model training from:  20090000 to  20160104\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.18044208288192748  minutes\n",
            "start: 63\n",
            "end:  126\n",
            "======A2C Validation from:  20160104 to  20160405\n",
            "A2C Sharpe Ratio:  0.08113033857196848\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5186728556950887  minutes\n",
            "======PPO Validation from:  20160104 to  20160405\n",
            "PPO Sharpe Ratio:  0.20964457440720624\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.25263214111328125  minutes\n",
            "======DDPG Validation from:  20160104 to  20160405\n",
            "======Trading from:  20160405 to  20160705\n",
            "previous_total_asset:1068309.3892576096\n",
            "end_total_asset:1074553.048876575\n",
            "total_reward:6243.65961896535\n",
            "total_cost:  6929.164684743504\n",
            "total trades:  1642\n",
            "Sharpe:  0.03213848213799619\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  88.40368850890555\n",
            "turbulence_threshold:  171.0940715631016\n",
            "train data start:  20090000\n",
            "train data end:  20160405\n",
            "validation data start:  20160405\n",
            "validation data end:  20160705\n",
            "======Model training from:  20090000 to  20160405\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.15634658734003704  minutes\n",
            "start: 126\n",
            "end:  189\n",
            "======A2C Validation from:  20160405 to  20160705\n",
            "A2C Sharpe Ratio:  -0.038491896935386155\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5066067258516948  minutes\n",
            "======PPO Validation from:  20160405 to  20160705\n",
            "PPO Sharpe Ratio:  0.0043997148498409995\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.25228743950525917  minutes\n",
            "======DDPG Validation from:  20160405 to  20160705\n",
            "======Trading from:  20160705 to  20161003\n",
            "previous_total_asset:1074553.048876575\n",
            "end_total_asset:1080558.2936656442\n",
            "total_reward:6005.244789069286\n",
            "total_cost:  1533.307800129449\n",
            "total trades:  845\n",
            "Sharpe:  0.032906124713531\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  63.02389190871245\n",
            "turbulence_threshold:  171.0940715631016\n",
            "train data start:  20090000\n",
            "train data end:  20160705\n",
            "validation data start:  20160705\n",
            "validation data end:  20161003\n",
            "======Model training from:  20090000 to  20160705\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.15764743487040203  minutes\n",
            "start: 189\n",
            "end:  252\n",
            "======A2C Validation from:  20160705 to  20161003\n",
            "A2C Sharpe Ratio:  -0.11201703931663877\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5004440665245056  minutes\n",
            "======PPO Validation from:  20160705 to  20161003\n",
            "PPO Sharpe Ratio:  -0.19391188192486897\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.25675849119822186  minutes\n",
            "======DDPG Validation from:  20160705 to  20161003\n",
            "======Trading from:  20161003 to  20170103\n",
            "previous_total_asset:1080558.2936656442\n",
            "end_total_asset:1186566.8066086755\n",
            "total_reward:106008.51294303127\n",
            "total_cost:  6299.479335486658\n",
            "total trades:  1628\n",
            "Sharpe:  0.4886501865905823\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  63.50003802482181\n",
            "turbulence_threshold:  171.0940715631016\n",
            "train data start:  20090000\n",
            "train data end:  20161003\n",
            "validation data start:  20161003\n",
            "validation data end:  20170103\n",
            "======Model training from:  20090000 to  20161003\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.16162421703338622  minutes\n",
            "start: 252\n",
            "end:  315\n",
            "======A2C Validation from:  20161003 to  20170103\n",
            "A2C Sharpe Ratio:  0.48878234814714777\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5193804184595744  minutes\n",
            "======PPO Validation from:  20161003 to  20170103\n",
            "PPO Sharpe Ratio:  0.6063640135440963\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.25307448307673136  minutes\n",
            "======DDPG Validation from:  20161003 to  20170103\n",
            "======Trading from:  20170103 to  20170404\n",
            "previous_total_asset:1186566.8066086755\n",
            "end_total_asset:1201090.1345699858\n",
            "total_reward:14523.327961310279\n",
            "total_cost:  8209.84571306376\n",
            "total trades:  1632\n",
            "Sharpe:  0.08624508887273434\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  98.73395137532273\n",
            "turbulence_threshold:  96.08032158358223\n",
            "train data start:  20090000\n",
            "train data end:  20170103\n",
            "validation data start:  20170103\n",
            "validation data end:  20170404\n",
            "======Model training from:  20090000 to  20170103\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.16300033728281657  minutes\n",
            "start: 315\n",
            "end:  378\n",
            "======A2C Validation from:  20170103 to  20170404\n",
            "A2C Sharpe Ratio:  0.1289306196093206\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5161020358403524  minutes\n",
            "======PPO Validation from:  20170103 to  20170404\n",
            "PPO Sharpe Ratio:  0.1159069366142896\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.25289040406545005  minutes\n",
            "======DDPG Validation from:  20170103 to  20170404\n",
            "======Trading from:  20170404 to  20170705\n",
            "previous_total_asset:1201090.1345699858\n",
            "end_total_asset:1208988.2832242756\n",
            "total_reward:7898.1486542897765\n",
            "total_cost:  6873.4455902788995\n",
            "total trades:  1386\n",
            "Sharpe:  0.07120755929288672\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  56.55371809374808\n",
            "turbulence_threshold:  171.0940715631016\n",
            "train data start:  20090000\n",
            "train data end:  20170404\n",
            "validation data start:  20170404\n",
            "validation data end:  20170705\n",
            "======Model training from:  20090000 to  20170404\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.15691282749176025  minutes\n",
            "start: 378\n",
            "end:  441\n",
            "======A2C Validation from:  20170404 to  20170705\n",
            "A2C Sharpe Ratio:  0.1220657798155169\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5161044875780741  minutes\n",
            "======PPO Validation from:  20170404 to  20170705\n",
            "PPO Sharpe Ratio:  0.24804818666016704\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.2527952233950297  minutes\n",
            "======DDPG Validation from:  20170404 to  20170705\n",
            "======Trading from:  20170705 to  20171003\n",
            "previous_total_asset:1208988.2832242756\n",
            "end_total_asset:1251635.7417291151\n",
            "total_reward:42647.45850483957\n",
            "total_cost:  9407.657117330129\n",
            "total trades:  1672\n",
            "Sharpe:  0.3435331271122462\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  79.0288064959022\n",
            "turbulence_threshold:  171.0940715631016\n",
            "train data start:  20090000\n",
            "train data end:  20170705\n",
            "validation data start:  20170705\n",
            "validation data end:  20171003\n",
            "======Model training from:  20090000 to  20170705\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.1676548441251119  minutes\n",
            "start: 441\n",
            "end:  504\n",
            "======A2C Validation from:  20170705 to  20171003\n",
            "A2C Sharpe Ratio:  0.32708366568481373\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5123425205548604  minutes\n",
            "======PPO Validation from:  20170705 to  20171003\n",
            "PPO Sharpe Ratio:  0.1138444862121586\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.2581219514211019  minutes\n",
            "======DDPG Validation from:  20170705 to  20171003\n",
            "======Trading from:  20171003 to  20180103\n",
            "previous_total_asset:1251635.7417291151\n",
            "end_total_asset:1374644.7369590146\n",
            "total_reward:123008.99522989942\n",
            "total_cost:  1562.474770365251\n",
            "total trades:  854\n",
            "Sharpe:  0.5674872663774029\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  102.51840320974976\n",
            "turbulence_threshold:  96.08032158358223\n",
            "train data start:  20090000\n",
            "train data end:  20171003\n",
            "validation data start:  20171003\n",
            "validation data end:  20180103\n",
            "======Model training from:  20090000 to  20171003\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.16834534804026285  minutes\n",
            "start: 504\n",
            "end:  567\n",
            "======A2C Validation from:  20171003 to  20180103\n",
            "A2C Sharpe Ratio:  0.40671547603723057\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5120184620221456  minutes\n",
            "======PPO Validation from:  20171003 to  20180103\n",
            "PPO Sharpe Ratio:  0.323001265935073\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.275427516301473  minutes\n",
            "======DDPG Validation from:  20171003 to  20180103\n",
            "======Trading from:  20180103 to  20180405\n",
            "previous_total_asset:1374644.7369590146\n",
            "end_total_asset:1409014.0756208801\n",
            "total_reward:34369.338661865564\n",
            "total_cost:  1921.5293544264991\n",
            "total trades:  219\n",
            "Sharpe:  0.1745108354062226\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  101.995510228318\n",
            "turbulence_threshold:  96.08032158358223\n",
            "train data start:  20090000\n",
            "train data end:  20180103\n",
            "validation data start:  20180103\n",
            "validation data end:  20180405\n",
            "======Model training from:  20090000 to  20180103\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.17331799666086833  minutes\n",
            "start: 567\n",
            "end:  630\n",
            "======A2C Validation from:  20180103 to  20180405\n",
            "A2C Sharpe Ratio:  -0.02728886380575488\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5371673981348674  minutes\n",
            "======PPO Validation from:  20180103 to  20180405\n",
            "PPO Sharpe Ratio:  0.022392951342620673\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.2660404046376546  minutes\n",
            "======DDPG Validation from:  20180103 to  20180405\n",
            "======Trading from:  20180405 to  20180705\n",
            "previous_total_asset:1409014.0756208801\n",
            "end_total_asset:1384512.0229504227\n",
            "total_reward:-24502.0526704574\n",
            "total_cost:  6566.652417766773\n",
            "total trades:  1114\n",
            "Sharpe:  -0.12004563868279453\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  118.80328323448445\n",
            "turbulence_threshold:  96.08032158358223\n",
            "train data start:  20090000\n",
            "train data end:  20180405\n",
            "validation data start:  20180405\n",
            "validation data end:  20180705\n",
            "======Model training from:  20090000 to  20180405\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.16982542276382445  minutes\n",
            "start: 630\n",
            "end:  693\n",
            "======A2C Validation from:  20180405 to  20180705\n",
            "A2C Sharpe Ratio:  -0.15462539220393598\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5276542425155639  minutes\n",
            "======PPO Validation from:  20180405 to  20180705\n",
            "PPO Sharpe Ratio:  -0.22134596908042647\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.2650365710258484  minutes\n",
            "======DDPG Validation from:  20180405 to  20180705\n",
            "======Trading from:  20180705 to  20181003\n",
            "previous_total_asset:1384512.0229504227\n",
            "end_total_asset:1398303.263144499\n",
            "total_reward:13791.240194076207\n",
            "total_cost:  5814.33094413466\n",
            "total trades:  663\n",
            "Sharpe:  0.10342105846488178\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  97.61339261089691\n",
            "turbulence_threshold:  96.08032158358223\n",
            "train data start:  20090000\n",
            "train data end:  20180705\n",
            "validation data start:  20180705\n",
            "validation data end:  20181003\n",
            "======Model training from:  20090000 to  20180705\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.17153432766596477  minutes\n",
            "start: 693\n",
            "end:  756\n",
            "======A2C Validation from:  20180705 to  20181003\n",
            "A2C Sharpe Ratio:  0.296089520559642\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.542192010084788  minutes\n",
            "======PPO Validation from:  20180705 to  20181003\n",
            "PPO Sharpe Ratio:  0.03488277443308439\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.2673871636390686  minutes\n",
            "======DDPG Validation from:  20180705 to  20181003\n",
            "======Trading from:  20181003 to  20190104\n",
            "previous_total_asset:1398303.263144499\n",
            "end_total_asset:1405090.784563301\n",
            "total_reward:6787.5214188019745\n",
            "total_cost:  735.0116027411483\n",
            "total trades:  174\n",
            "Sharpe:  0.3115739926951904\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  93.72777571659744\n",
            "turbulence_threshold:  171.0940715631016\n",
            "train data start:  20090000\n",
            "train data end:  20181003\n",
            "validation data start:  20181003\n",
            "validation data end:  20190104\n",
            "======Model training from:  20090000 to  20181003\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.17835201422373453  minutes\n",
            "start: 756\n",
            "end:  819\n",
            "======A2C Validation from:  20181003 to  20190104\n",
            "A2C Sharpe Ratio:  -0.39444687055958183\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5355308572451274  minutes\n",
            "======PPO Validation from:  20181003 to  20190104\n",
            "PPO Sharpe Ratio:  -0.38454711331757957\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.2724623759587606  minutes\n",
            "======DDPG Validation from:  20181003 to  20190104\n",
            "======Trading from:  20190104 to  20190405\n",
            "previous_total_asset:1405090.784563301\n",
            "end_total_asset:1407932.127254576\n",
            "total_reward:2841.3426912750583\n",
            "total_cost:  9671.460856521635\n",
            "total trades:  1591\n",
            "Sharpe:  0.01616250665166103\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  123.0262224864589\n",
            "turbulence_threshold:  96.08032158358223\n",
            "train data start:  20090000\n",
            "train data end:  20190104\n",
            "validation data start:  20190104\n",
            "validation data end:  20190405\n",
            "======Model training from:  20090000 to  20190104\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.17629304726918538  minutes\n",
            "start: 819\n",
            "end:  882\n",
            "======A2C Validation from:  20190104 to  20190405\n",
            "A2C Sharpe Ratio:  0.008435292088734055\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5324054042498271  minutes\n",
            "======PPO Validation from:  20190104 to  20190405\n",
            "PPO Sharpe Ratio:  0.03136561393843588\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.25882887045542396  minutes\n",
            "======DDPG Validation from:  20190104 to  20190405\n",
            "======Trading from:  20190405 to  20190708\n",
            "previous_total_asset:1407932.127254576\n",
            "end_total_asset:1411014.2473764687\n",
            "total_reward:3082.1201218927745\n",
            "total_cost:  1272.931476310465\n",
            "total trades:  120\n",
            "Sharpe:  0.16116270439958344\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  118.38041179921193\n",
            "turbulence_threshold:  96.08032158358223\n",
            "train data start:  20090000\n",
            "train data end:  20190405\n",
            "validation data start:  20190405\n",
            "validation data end:  20190708\n",
            "======Model training from:  20090000 to  20190405\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.16908320585886638  minutes\n",
            "start: 882\n",
            "end:  945\n",
            "======A2C Validation from:  20190405 to  20190708\n",
            "A2C Sharpe Ratio:  0.2817702615442658\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5402818600336711  minutes\n",
            "======PPO Validation from:  20190405 to  20190708\n",
            "PPO Sharpe Ratio:  0.05341412093647586\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.27633264859517415  minutes\n",
            "======DDPG Validation from:  20190405 to  20190708\n",
            "======Trading from:  20190708 to  20191004\n",
            "previous_total_asset:1411014.2473764687\n",
            "end_total_asset:1413179.446766726\n",
            "total_reward:2165.199390257243\n",
            "total_cost:  1893.0536489553167\n",
            "total trades:  362\n",
            "Sharpe:  0.033778701399822926\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  151.23640414160957\n",
            "turbulence_threshold:  96.08032158358223\n",
            "train data start:  20090000\n",
            "train data end:  20190708\n",
            "validation data start:  20190708\n",
            "validation data end:  20191004\n",
            "======Model training from:  20090000 to  20190708\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.1736846923828125  minutes\n",
            "start: 945\n",
            "end:  1008\n",
            "======A2C Validation from:  20190708 to  20191004\n",
            "A2C Sharpe Ratio:  -0.16816668503783527\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5525370279947917  minutes\n",
            "======PPO Validation from:  20190708 to  20191004\n",
            "PPO Sharpe Ratio:  -0.2001391746116389\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.26378730138142903  minutes\n",
            "======DDPG Validation from:  20190708 to  20191004\n",
            "======Trading from:  20191004 to  20200106\n",
            "previous_total_asset:1413179.446766726\n",
            "end_total_asset:1411371.8956153197\n",
            "total_reward:-1807.5511514062528\n",
            "total_cost:  410.331629828415\n",
            "total trades:  56\n",
            "Sharpe:  -0.3831395077384055\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  114.43661563283563\n",
            "turbulence_threshold:  96.08032158358223\n",
            "train data start:  20090000\n",
            "train data end:  20191004\n",
            "validation data start:  20191004\n",
            "validation data end:  20200106\n",
            "======Model training from:  20090000 to  20191004\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.1653493920962016  minutes\n",
            "start: 1008\n",
            "end:  1071\n",
            "======A2C Validation from:  20191004 to  20200106\n",
            "A2C Sharpe Ratio:  -0.2909864754103558\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5289200226465861  minutes\n",
            "======PPO Validation from:  20191004 to  20200106\n",
            "PPO Sharpe Ratio:  -0.34280589125860617\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.26590177218119304  minutes\n",
            "======DDPG Validation from:  20191004 to  20200106\n",
            "======Trading from:  20200106 to  20200406\n",
            "previous_total_asset:1411371.8956153197\n",
            "end_total_asset:1400452.6055365237\n",
            "total_reward:-10919.29007879598\n",
            "total_cost:  729.2014196012211\n",
            "total trades:  177\n",
            "Sharpe:  -0.4356581634491328\n",
            "============================================\n",
            "insample turbulence threshold:  96.08032158358223\n",
            "historic turbulence mean:  119.62372266762043\n",
            "turbulence_threshold:  96.08032158358223\n",
            "train data start:  20090000\n",
            "train data end:  20200106\n",
            "validation data start:  20200106\n",
            "validation data end:  20200406\n",
            "======Model training from:  20090000 to  20200106\n",
            "======A2C Training========\n",
            "Training time (A2C):  0.16851201852162678  minutes\n",
            "start: 1071\n",
            "end:  1134\n",
            "======A2C Validation from:  20200106 to  20200406\n",
            "A2C Sharpe Ratio:  -0.39843994814669215\n",
            "======PPO Training========\n",
            "Training time (PPO):  0.5623007814089457  minutes\n",
            "======PPO Validation from:  20200106 to  20200406\n",
            "PPO Sharpe Ratio:  -0.4590996252855707\n",
            "======DDPG Training========\n",
            "Training time (DDPG):  0.2657423973083496  minutes\n",
            "======DDPG Validation from:  20200106 to  20200406\n",
            "======Trading from:  20200406 to  20200707\n",
            "previous_total_asset:1400452.6055365237\n",
            "end_total_asset:1403398.5369881\n",
            "total_reward:2945.9314515762962\n",
            "total_cost:  515.1550099079464\n",
            "total trades:  138\n",
            "Sharpe:  0.14818889247174216\n",
            "Ensemble Strategy took:  17.596149361133577  minutes\n"
          ]
        }
      ],
      "source": [
        "model_used, a2c_list, ppo_list, ddpg_list =run_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "YvqhnRjfuoGz",
        "outputId": "809c6ade-850c-4758-8a29-157bab18f266"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['DDPG', 'PPO', 'DDPG', 'A2C', 'PPO', 'A2C', 'PPO', 'DDPG', 'DDPG', 'PPO', 'DDPG', 'A2C', 'PPO', 'DDPG', 'A2C', 'DDPG', 'A2C', 'A2C'] [0.02741843321550068, 0.08113033857196848, -0.038491896935386155, -0.11201703931663877, 0.48878234814714777, 0.1289306196093206, 0.1220657798155169, 0.32708366568481373, 0.40671547603723057, -0.02728886380575488, -0.15462539220393598, 0.296089520559642, -0.39444687055958183, 0.008435292088734055, 0.2817702615442658, -0.16816668503783527, -0.2909864754103558, -0.39843994814669215] [-0.06593909665749961, 0.20964457440720624, 0.0043997148498409995, -0.19391188192486897, 0.6063640135440963, 0.1159069366142896, 0.24804818666016704, 0.1138444862121586, 0.323001265935073, 0.022392951342620673, -0.22134596908042647, 0.03488277443308439, -0.38454711331757957, 0.03136561393843588, 0.05341412093647586, -0.2001391746116389, -0.34280589125860617, -0.4590996252855707] [0.1059923983580373, 0.12988831239713342, 0.014094043881650493, -0.11567937135449254, 0.4290174953951317, 0.12469152995419162, 0.21701834549448562, 0.458828248904225, 0.6590130030928272, -0.010146416355113317, -0.08213867046605419, 0.24585160432925884, -0.3854154884251965, 0.07395353136396317, 0.2277845505432327, 0.05013271998171108, -0.38038546728158973, -0.4396761275723462]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-644448e9-45fc-4549-a1a1-3fc782d388d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_used</th>\n",
              "      <th>a2c_sr</th>\n",
              "      <th>ppo_sr</th>\n",
              "      <th>ddpg_sr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>0.027418</td>\n",
              "      <td>-0.065939</td>\n",
              "      <td>0.105992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.081130</td>\n",
              "      <td>0.209645</td>\n",
              "      <td>0.129888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PPO</td>\n",
              "      <td>-0.038492</td>\n",
              "      <td>0.004400</td>\n",
              "      <td>0.014094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.112017</td>\n",
              "      <td>-0.193912</td>\n",
              "      <td>-0.115679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A2C</td>\n",
              "      <td>0.488782</td>\n",
              "      <td>0.606364</td>\n",
              "      <td>0.429017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-644448e9-45fc-4549-a1a1-3fc782d388d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-644448e9-45fc-4549-a1a1-3fc782d388d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-644448e9-45fc-4549-a1a1-3fc782d388d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  model_used    a2c_sr    ppo_sr   ddpg_sr\n",
              "0             0.027418 -0.065939  0.105992\n",
              "1       DDPG  0.081130  0.209645  0.129888\n",
              "2        PPO -0.038492  0.004400  0.014094\n",
              "3       DDPG -0.112017 -0.193912 -0.115679\n",
              "4        A2C  0.488782  0.606364  0.429017"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(model_used, a2c_list, ppo_list, ddpg_list)\n",
        "model_result = pd.DataFrame()\n",
        "\n",
        "\n",
        "model_result['model_used'] = [\" \"] + model_used\n",
        "model_result['a2c_sr'] = a2c_list + [0.0]\n",
        "model_result['ppo_sr'] = ppo_list + [0.0]\n",
        "model_result['ddpg_sr'] = ddpg_list + [0.0]\n",
        "\n",
        "model_result.to_csv('results/model_result_3_month.csv', index=False)\n",
        "\n",
        "model_result.head()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-cUyZhtnVqA",
        "outputId": "1642aa2f-47d9-41c1-8e5a-e85ef8dd395f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/quantopian/pyfolio\n",
            "  Cloning https://github.com/quantopian/pyfolio to /tmp/pip-req-build-oy4hxvlr\n",
            "  Running command git clone -q https://github.com/quantopian/pyfolio /tmp/pip-req-build-oy4hxvlr\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (5.5.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (3.1.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (1.16.4)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (1.0.3)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (2022.1)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (0.21.0)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (0.11.2)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio==0.9.2+75.g4b901f6) (0.5.5)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (0.9.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (41.6.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (5.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (3.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.0->pyfolio==0.9.2+75.g4b901f6) (4.1.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (2.23.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (4.2.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio==0.9.2+75.g4b901f6) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16.1->pyfolio==0.9.2+75.g4b901f6) (0.15.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=3.2.3->pyfolio==0.9.2+75.g4b901f6) (0.7.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.0.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.16.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
            "Requirement already satisfied: matplotlib==3.1.1 in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1) (3.0.8)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1) (1.16.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.1.1) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.1.1) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.16.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/quantopian/pyfolio\n",
        "!pip install pandas\n",
        "!pip install matplotlib==3.1.1\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "hw-HeNe2nMsp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pyfolio\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "DFjxoy5icAGU"
      },
      "outputs": [],
      "source": [
        "def get_daily_return(df):\n",
        "    df['daily_return']=df.account_value.pct_change(1)\n",
        "    #df=df.dropna()\n",
        "    print('Sharpe: ',(252**0.5)*df['daily_return'].mean()/ df['daily_return'].std())\n",
        "    return df\n",
        "\n",
        "\n",
        "def backtest_strat(df):\n",
        "    strategy_ret= df.copy()\n",
        "    strategy_ret['Date'] = pd.to_datetime(strategy_ret['Date'])\n",
        "    strategy_ret.set_index('Date', drop = False, inplace = True)\n",
        "    strategy_ret.index = strategy_ret.index.tz_localize('UTC')\n",
        "    del strategy_ret['Date']\n",
        "    ts = pd.Series(strategy_ret['daily_return'].values, index=strategy_ret.index)\n",
        "    return ts\n",
        "\n",
        "\n",
        "def get_account_value(model_name):\n",
        "    df_account_value=pd.DataFrame()\n",
        "    for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
        "        temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format(model_name,i))\n",
        "        df_account_value = df_account_value.append(temp,ignore_index=True)\n",
        "    df_account_value = pd.DataFrame({'account_value':df_account_value['0']})\n",
        "    sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
        "    print(sharpe)\n",
        "    df_account_value=df_account_value.join(df_trade_date[63:].reset_index(drop=True))\n",
        "    return df_account_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dji = pd.read_csv(\"data/^DJI.csv\")\n",
        "test_dji=dji[(dji['Date']>='2016-01-01') & (dji['Date']<='2020-06-30')]\n",
        "test_dji = test_dji.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYTItCTknqmB",
        "outputId": "40903f5d-7c01-4c65-8d04-6f5b83e62064"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1131, 8)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dji.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pUatjv5_xg-3",
        "outputId": "757804a3-128d-440a-a22f-03fa48840af1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1d5826ed-5374-4044-a1ed-cd5173a3eddb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>daily_return</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-04</td>\n",
              "      <td>17405.480469</td>\n",
              "      <td>17405.480469</td>\n",
              "      <td>16957.630859</td>\n",
              "      <td>17148.939453</td>\n",
              "      <td>17148.939453</td>\n",
              "      <td>148060000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>17147.500000</td>\n",
              "      <td>17195.839844</td>\n",
              "      <td>17038.609375</td>\n",
              "      <td>17158.660156</td>\n",
              "      <td>17158.660156</td>\n",
              "      <td>105750000</td>\n",
              "      <td>0.000567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-06</td>\n",
              "      <td>17154.830078</td>\n",
              "      <td>17154.830078</td>\n",
              "      <td>16817.619141</td>\n",
              "      <td>16906.509766</td>\n",
              "      <td>16906.509766</td>\n",
              "      <td>120250000</td>\n",
              "      <td>-0.014695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-07</td>\n",
              "      <td>16888.359375</td>\n",
              "      <td>16888.359375</td>\n",
              "      <td>16463.630859</td>\n",
              "      <td>16514.099609</td>\n",
              "      <td>16514.099609</td>\n",
              "      <td>176240000</td>\n",
              "      <td>-0.023211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-08</td>\n",
              "      <td>16519.169922</td>\n",
              "      <td>16651.890625</td>\n",
              "      <td>16314.570313</td>\n",
              "      <td>16346.450195</td>\n",
              "      <td>16346.450195</td>\n",
              "      <td>141850000</td>\n",
              "      <td>-0.010152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d5826ed-5374-4044-a1ed-cd5173a3eddb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d5826ed-5374-4044-a1ed-cd5173a3eddb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d5826ed-5374-4044-a1ed-cd5173a3eddb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Date          Open          High           Low         Close  \\\n",
              "0  2016-01-04  17405.480469  17405.480469  16957.630859  17148.939453   \n",
              "1  2016-01-05  17147.500000  17195.839844  17038.609375  17158.660156   \n",
              "2  2016-01-06  17154.830078  17154.830078  16817.619141  16906.509766   \n",
              "3  2016-01-07  16888.359375  16888.359375  16463.630859  16514.099609   \n",
              "4  2016-01-08  16519.169922  16651.890625  16314.570313  16346.450195   \n",
              "\n",
              "      Adj Close     Volume  daily_return  \n",
              "0  17148.939453  148060000           NaN  \n",
              "1  17158.660156  105750000      0.000567  \n",
              "2  16906.509766  120250000     -0.014695  \n",
              "3  16514.099609  176240000     -0.023211  \n",
              "4  16346.450195  141850000     -0.010152  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dji.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "eF8dK72JoSnu"
      },
      "outputs": [],
      "source": [
        "test_dji['daily_return']=test_dji['Adj Close'].pct_change(1)\n",
        "\n",
        "dow_strat = backtest_strat(test_dji)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "wqXc8hweoYXw"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/dow_30_2009_2020.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "46KmuQCSocVR"
      },
      "outputs": [],
      "source": [
        "rebalance_window = 63\n",
        "validation_window = 63\n",
        "unique_trade_date = df[(df.datadate > 20151001)&(df.datadate <= 20200707)].datadate.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "s9n7n_WEofNH"
      },
      "outputs": [],
      "source": [
        "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgDDRhqJoht9",
        "outputId": "c677f9f7-d78e-4426-898e-83c0f76890de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9964521180441215\n"
          ]
        }
      ],
      "source": [
        "ensemble_account_value = get_account_value('ensemble')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM3NY7DklyVt",
        "outputId": "82748f0c-0898-4d2c-a0ff-9d751c2fa060"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1134, 2)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_account_value.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yrOXAufUlq3N",
        "outputId": "c9609924-d7d0-453a-a04c-2ce871536c59"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-81bdb7be-b6d5-43c5-ad5e-e369a5f75ec9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_value</th>\n",
              "      <th>datadate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000000.000000</td>\n",
              "      <td>20160104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>999503.341670</td>\n",
              "      <td>20160105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>996295.965896</td>\n",
              "      <td>20160106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>988540.721064</td>\n",
              "      <td>20160107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>984334.794150</td>\n",
              "      <td>20160108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81bdb7be-b6d5-43c5-ad5e-e369a5f75ec9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81bdb7be-b6d5-43c5-ad5e-e369a5f75ec9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81bdb7be-b6d5-43c5-ad5e-e369a5f75ec9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    account_value  datadate\n",
              "0  1000000.000000  20160104\n",
              "1   999503.341670  20160105\n",
              "2   996295.965896  20160106\n",
              "3   988540.721064  20160107\n",
              "4   984334.794150  20160108"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_account_value.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4TB3HoNqEFd",
        "outputId": "a5d62190-a044-45fa-c6d3-e2d601ede916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sharpe:  0.9964521180441215\n"
          ]
        }
      ],
      "source": [
        "ensemble_account_value = get_daily_return(ensemble_account_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Jm5PAe3xl1eg"
      },
      "outputs": [],
      "source": [
        "ensemble_account_value.to_csv('results/ensemble_3_month.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "tPNSbRgoqGPF"
      },
      "outputs": [],
      "source": [
        "ensemble_account_value['Date'] = test_dji['Date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "xeQYrBv_qccY"
      },
      "outputs": [],
      "source": [
        "ensemble_strat = backtest_strat(ensemble_account_value[0:1097])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "looNHg8PyAw8",
        "outputId": "da4df51e-0e86-4463-ee2f-0d2ea624c64b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Date\n",
              "2016-01-04 00:00:00+00:00         NaN\n",
              "2016-01-05 00:00:00+00:00   -0.000497\n",
              "2016-01-06 00:00:00+00:00   -0.003209\n",
              "2016-01-07 00:00:00+00:00   -0.007784\n",
              "2016-01-08 00:00:00+00:00   -0.004255\n",
              "                               ...   \n",
              "2020-05-06 00:00:00+00:00    0.000000\n",
              "2020-05-07 00:00:00+00:00    0.000000\n",
              "2020-05-08 00:00:00+00:00    0.000000\n",
              "2020-05-11 00:00:00+00:00    0.000000\n",
              "2020-05-12 00:00:00+00:00    0.000000\n",
              "Length: 1097, dtype: float64"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_strat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "id": "XU8btaAyqfKn",
        "outputId": "5a5f8f35-1840-401f-ecfc-6389ec693baa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2016-01-04</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2020-05-12</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>52</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>8.02%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>39.913%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>8.007%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>1.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-5.82%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>1.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>1.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>1.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-0.977%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alpha</th>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Beta</th>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-a52d818bc8d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mpyfolio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpyfolio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_full_tear_sheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble_strat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdow_strat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyfolio/tears.py\u001b[0m in \u001b[0;36mcreate_full_tear_sheet\u001b[0;34m(returns, positions, transactions, market_data, benchmark_rets, slippage, live_start_date, sector_mappings, round_trips, estimate_intraday, hide_positions, cone_std, bootstrap, unadjusted_returns, turnover_denom, set_context, factor_returns, factor_loadings, pos_in_dollars, header_rows, factor_partitions)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mturnover_denom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mturnover_denom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mheader_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         set_context=set_context)\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     create_interesting_times_tear_sheet(returns,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyfolio/plotting.py\u001b[0m in \u001b[0;36mcall_w_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_w_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyfolio/tears.py\u001b[0m in \u001b[0;36mcreate_returns_tear_sheet\u001b[0;34m(returns, positions, transactions, live_start_date, cone_std, benchmark_rets, bootstrap, turnover_denom, header_rows, return_fig)\u001b[0m\n\u001b[1;32m    472\u001b[0m                              header_rows=header_rows)\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m     \u001b[0mplotting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_worst_drawdown_periods\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0mvertical_sections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyfolio/plotting.py\u001b[0m in \u001b[0;36mshow_worst_drawdown_periods\u001b[0;34m(returns, top)\u001b[0m\n\u001b[1;32m   1669\u001b[0m     \"\"\"\n\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1671\u001b[0;31m     \u001b[0mdrawdown_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_drawdown_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1672\u001b[0m     utils.print_table(\n\u001b[1;32m   1673\u001b[0m         \u001b[0mdrawdown_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Net drawdown in %'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyfolio/timeseries.py\u001b[0m in \u001b[0;36mgen_drawdown_table\u001b[0;34m(returns, top)\u001b[0m\n\u001b[1;32m    997\u001b[0m                                          \u001b[0;34m'Valley date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                                          \u001b[0;34m'Recovery date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m                                          'Duration'])\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpeak\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalley\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecovery\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrawdown_periods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    433\u001b[0m             )\n\u001b[1;32m    434\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0mnan_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_1d_arraylike_from_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mconstruct_1d_arraylike_from_scalar\u001b[0;34m(value, length, dtype)\u001b[0m\n\u001b[1;32m   1438\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1440\u001b[0;31m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'object' has no attribute 'dtype'"
          ]
        }
      ],
      "source": [
        "with pyfolio.plotting.plotting_context(font_scale=1.1):\n",
        "    pyfolio.create_full_tear_sheet(returns = ensemble_strat, benchmark_rets=dow_strat, set_context=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "ensemble_strategy_experiment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
